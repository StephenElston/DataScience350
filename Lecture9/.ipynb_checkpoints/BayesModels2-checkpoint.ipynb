{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Modeling and Markov Chain Monte Carlo\n",
    "\n",
    "### Data Science 350\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook introduces you to a general and flexible form of Bayesian modeling using the **Makov chain Monte Carlo** methods. \n",
    "\n",
    "![](img/Flips.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Review of Bayes Theorem\n",
    "\n",
    "Recall Bayes theorem:\n",
    "\n",
    "$$P(A|B) = \\frac{P(A)P(B|A)}{P(B)}$$\n",
    "\n",
    "Computing the normalization $P(B)$ is a bit of a mess. But fortunately, we don't always need the denominator. We can rewrite Bayes Theorem as:\n",
    "\n",
    "$$𝑃(𝐴│𝐵)=𝑘∙𝑃(𝐵|𝐴)𝑃(𝐴)$$\n",
    "\n",
    "Ignoring the normalizaton constant $k$, we get:\n",
    "\n",
    "$$𝑃(𝐴│𝐵) \\propto 𝑃(𝐵|𝐴)𝑃(𝐴)$$\n",
    "\n",
    "### Bayesian parameter estimation\n",
    "\n",
    "How to we interpret the relationships shown above? We do this as follows:\n",
    "\n",
    "$$Posterior\\ Distribution \\propto Likelihood \\bullet Prior\\ Distribution \\\\\n",
    "Or\\\\\n",
    "𝑃(𝑝𝑎𝑟𝑎𝑚𝑒𝑡𝑒𝑟𝑠│𝑑𝑎𝑡𝑎) \\propto 𝑃(𝑑𝑎𝑡𝑎|𝑝𝑎𝑟𝑎𝑚𝑒𝑡𝑒𝑟𝑠)𝑃(𝑝𝑎𝑟𝑎𝑚𝑒𝑡𝑒𝑟𝑠) $$\n",
    "\n",
    "These relationships apply to the observed data distributions, or to parameters in a model (partial slopes, intercept, error distributions, lasso constant,…). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequentist by Bayesian models\n",
    "\n",
    "Let's summarize the differences between the Baysian and Frequentist views. \n",
    "\n",
    "- Bayesian methods use priors to quantify what we know about parameters.\n",
    "- Frequentists do not quantify anything about the parameters, using p-values and confidence intervals to express the unknowns about parameters.\n",
    "\n",
    "Accepting that both views are useful, we can contrast these methods with a chart.\n",
    "\n",
    "![](img/FrequentistBayes.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Sampling and Scalability\n",
    "\n",
    "Real-world Bayes models have large numbers of parameters, even into the millions. As a naive approach to Bayesian analysis would be to simply grid sample across the dimensions of the parameter space. However, grid sampling will not scale. To underestand the scaling problem, do the following thought experiment, where each dimension is sampled 100 times:\n",
    "\n",
    "- For a 1-parameter model: $100$ samples.\n",
    "- For a 2-parameter model: $100^2 = 10000$ samples.\n",
    "- For a 3-parameter model: $100^3 = 10^5$ samples.\n",
    "- For a 100-parameter model: $100^{100} = 100^{102}$ samples. \n",
    "\n",
    "As you can see, the compuational complexity of grid sampling has **exponential scaling** with dimensionality. Clearly, we need a better approach. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Markov Chain Monte Carlo\n",
    "\n",
    "Large-scale Bayesian models use a family of efficient sampling methods known as **Markov chain Monte Carlo sampling**. MCMC methods are compuationally efficient, but requires some effort to understand how it works and  what to do when things go wrong. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### What is a Markov process?\n",
    "\n",
    "As you might guess, a MCMC sampling uses a chain of **Markov sampling processes**. The chain is built from a sequence of individul Markov processes. A Markov process is any process that a makes a transition from one state other states with probability $\\Pi$ with **no dependency on past states**. In summary, a Markov process has the  following properties:\n",
    "- $\\Pi$  only depends on the current state\n",
    "- Transition from current state to one or more other states\n",
    "- Can ‘transition’ to current state\n",
    "- A matrix $\\Pi$ of dim N X N for N possible state transistions\n",
    "- A Markov procecss is a random walk since any possible transition to a new state, $j$, can occur from each state, $i$, if $p_{ij} \\gt 0$.\n",
    "\n",
    "Since a Markov chain is a **memoryless** sequence of Markov transition processes, we can write:\n",
    "\n",
    "$$P(X_{t + 1}| X_t = x_t, \\ldots, x_0 = x_t) = p(X_{t + 1}| x_t)$$\n",
    "\n",
    "Since the Markov process is memoryless, the transition probability only depends on the current state, not any previous states. \n",
    "\n",
    "For a system with $N$ possible states we can write the transition matrix $\\Pi$ for the probaility of transition from one state to another:\n",
    "\n",
    "$$\\Pi = \n",
    "\\begin{bmatrix}\n",
    "\\pi_{1,1} & \\pi_{1,2} & \\cdots & \\pi_{1, N}\\\\\n",
    "\\pi_{2,1} & \\pi_{2,2} & \\cdots & \\pi_{2,N}\\\\\n",
    "\\cdots & \\cdots & \\cdots & \\cdots \\\\\n",
    "\\pi_{N,i} & \\pi_{N,2} & \\cdots & \\pi_{N,N}\n",
    "\\end{bmatrix}\\\\\n",
    "where\\\\\n",
    "\\pi_{i,j} = probability\\ of\\ transition\\ from\\ state\\ i\\ to\\ state\\ j\\\\\n",
    "and\\\\\n",
    "\\pi_{i,i} = probability\\ of\\ staying\\ in\\ state\\ i\\\\\n",
    "further\\\\\n",
    "\\pi_{i,j} \\ne \\pi_{j,i}\\ in\\ general\n",
    "$$\n",
    "\n",
    "Notice that none of these probabilities depend on the previous state history."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MCMC and the Metropolis Algorithm\n",
    "\n",
    "The first MCMC sampling algorithm developed is the **Metropolis Hastings algorithm** (Metropolis et al. (1953), Hastings (1970)). This algorithm is often referred to as the Metropolis algorithm. The Metropolis algorithm has the following steps to estimate the density of the likelihood of the parameters:\n",
    "1. Pick a starting point in your parameter space and evaluate the posterior according to your model. In other words, take an initial sample of the likelihood $p(data|parameters)$.\n",
    "2. Choose a nearby point in parameter space randomly and evaluate the likelihood at this point. A probability distribution is used to make this random selection. The Normal distribution is a common choice.\n",
    "  - If the $p(data | parameters)$ of the new point is greater than your current point, accept new point and move there.\n",
    "  - If the $p(data | parameters)$ of the new point is less than your current point, only accept with probability according to the ratio:  \n",
    "$$Acceptance\\ probability\\ = \\frac{p(data | new\\ parameters)}{p(data | previous\\ parameters)}$$.\n",
    "3. Repeat step 2 many times.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have outlined the basic Metropolois MCMC algorithm, let's examine some of its properties.\n",
    "\n",
    "- Since the M-H algorithm samples the parameter space we only need to visit a limited number of points, rather than sample an entire grid. \n",
    "- The M-H algorithm is guaranteed to **eventually converge** to the underlying distribution.\n",
    "- If there is high serial correlation from one sample to the next in M-H chain converges slowly. \n",
    "- To ensure efficient convergence we Need to ‘tune’ the state selection probability distribution used to find the next point. For example if we use Normal distribution we must pick $\\sigma$. If $\\sigma$ is too small, the chain will only search the space slowly, with small jumps. If $\\sigma$ is too big, there are large jumps which slow convergence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### M-H algorithm example\n",
    "\n",
    "Let's make these concepts concrete, by trying a simple example.\n",
    "\n",
    "As a first step, lets plot a set of points with density determined by the a bi-variate Normal distribution. Execute the code below and examine the resulting plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "library(MASS)\n",
    "random_points = mvrnorm(10000, mu=c(0.5,0.5), Sigma=matrix(c(1,0.6,0.6,1), nrow=2))\n",
    "plot(random_points[,1], random_points[,2], xlim=c(-4,4), ylim=c(-4,4), col=rgb(0,0,0,0.25),\n",
    "     main = 'Draws from a bivariate Normal distribution', \n",
    "    xlab = 'X', ylab = 'Y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "This plot looks as expected. The density of the dots is proportional to the probabilities. You can see the effect of the covariance structure in these data.\n",
    "\n",
    "As a next step, let's look at the density of the marginal probabilites of the $X$ and $Y$ variables. The code in the cell below plots histogram and density plots of the marginals. Execute this code and examine the result. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "par(mfrow = c(2,1))\n",
    "hist(random_points[,1], freq = FALSE, breaks = 40,\n",
    "     main = 'Marginal X distribution', \n",
    "     xlab = 'X')\n",
    "lines(density(random_points[,1]))\n",
    "hist(random_points[,2], freq = FALSE, breaks = 40,\n",
    "     main = 'Marginal Y distribution', \n",
    "     xlab = 'Y') \n",
    "lines(density(random_points[,2]))\n",
    "par(mfrow = c(1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that these distributions are approimately Normal, but with a right skew. \n",
    "\n",
    "Now, we are ready to sample these data using the M-H MCMC algorithm. The code in the cell below performs the following operations:\n",
    "\n",
    "1. Compute the likelihood of the bi-variate Normal distribution. \n",
    "2. Initialize the chain.\n",
    "3. Initialize some performance statistics.\n",
    "4. Sample the likelihood of the data using the M-H algorithm.\n",
    "5. Plot the result.\n",
    "\n",
    "Execute this code and examine the result. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Given a point, our value at that point(x,y) will be the \n",
    "# value of the distribution at x,y:\n",
    "likelihood = function(x,y){\n",
    "  sigma = matrix(c(1,0.6,0.6,1), nrow=2)\n",
    "  mu = c(0.5,0.5)\n",
    "  dist = c(x,y) - mu\n",
    "  value = (1/sqrt(4*pi^2**det(sigma))) * exp((-1/2) * t(dist) %*% ginv(sigma) %*% t(t(dist)) )\n",
    "  return(value)\n",
    "}\n",
    "\n",
    "# Where to start:\n",
    "x_chain = 4\n",
    "y_chain = -4\n",
    "# Chain length:\n",
    "chain_length = 10000\n",
    "\n",
    "#Evaluate current position:\n",
    "current_val = likelihood(x_chain,y_chain)\n",
    "current_val\n",
    "\n",
    "# Standard deviation of how far out to propose:\n",
    "proposal_sd = .1\n",
    "\n",
    "# Keep track of things:\n",
    "accept_count = 0\n",
    "reject_count = 0\n",
    "\n",
    "\n",
    "for (n in 1:(chain_length-1)){ # chain length minus 1 because we already have a point (the starting point)\n",
    "  proposed_x = x_chain[n] + rnorm(1, mean=0, sd=proposal_sd)\n",
    "  proposed_y = y_chain[n] + rnorm(1, mean=0, sd=proposal_sd)\n",
    "  proposed_val = likelihood(proposed_x, proposed_y)\n",
    "  \n",
    "  # Accept according to probability:\n",
    "  if (runif(1) < (proposed_val/current_val)){\n",
    "    x_chain = c(x_chain, proposed_x)\n",
    "    y_chain = c(y_chain, proposed_y)\n",
    "    current_val = proposed_val\n",
    "    accept_count = accept_count + 1\n",
    "  }else{\n",
    "    x_chain = c(x_chain, x_chain[n])\n",
    "    y_chain = c(y_chain, y_chain[n])\n",
    "    reject_count = reject_count + 1\n",
    "  } \n",
    "}\n",
    "\n",
    "plot(x_chain, y_chain, col=rgb(0,0,0,0.25), xlim=c(-4,4), ylim=c(-4,4),\n",
    "     main=\"MCMC values for a Bivariate Normal\", xlab=\"x\", ylab=\"y\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the long 'tail' on the sampled distribution. This behavior arrises from the initial wandering of the Markov chain as it finds the high probability regions of the distribution. This period in which the Markov chain wanders is known as the **burn-in period**.\n",
    "\n",
    "The code in the cell below, plots the same Markov chain, but with the first 1000 values removed. The remaining samples are from the post burn-in chain. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Burn in problem.  Solution?  Throw away first part of chain.\n",
    "num_burnin = round(0.1*chain_length)\n",
    "num_burnin\n",
    "\n",
    "plot(x_chain[num_burnin:chain_length], y_chain[num_burnin:chain_length],\n",
    "     col=rgb(0,0,0,0.25), xlim=c(-4,4), ylim=c(-4,4),\n",
    "     main=\"MCMC values for a Bivariate Normal with burn-in\", xlab=\"x\", ylab=\"y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "In the plot above you can see that there is no 'tail' in the sampled distribution. As expected, the tail was sampled during the burn-in period and was not significant in sampling the distribution.\n",
    "\n",
    "Let's plot the density of the marginal distribution of these samples. We can then compaire these densities to those of the orginal data we generated. The code in the cell below plots a histogram of the sampled marginal distributions along with the density of the original samples. Execute this code and compaire the results.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "par(mfrow = c(2,1))\n",
    "hist(x_chain[num_burnin:chain_length], freq = FALSE, breaks = 40,\n",
    "     main = 'Marginal X distribution', \n",
    "     xlab = 'X')\n",
    "lines(density(random_points[,1]))\n",
    "hist(y_chain[num_burnin:chain_length], freq = FALSE, breaks = 40,\n",
    "     main = 'Marginal y distribution', \n",
    "     xlab = 'X') \n",
    "lines(density(random_points[,2]))\n",
    "par(mfrow = c(1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Notice that the histograms of the sampled marginal distributions are close to the margianl density of the original data. There is some skew as a result of sampling error.\n",
    "\n",
    "Next, lets compare the **Maximum a posteriori or MAP** point of the sampled marginal distributions to the original means for $x$ and $y$. The code in the cell below approximates the MAP using the `mean` function. Execute this code and compaire the results to the original data with $x = 0.5$ and $y = 0.5$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Estimate bivariate MAP from chain:\n",
    "mcmc_map = c(mean(x_chain), mean(y_chain))\n",
    "mcmc_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The MAP values of the sampled marginal distributions are close to the values for the original data. However, the mean approximation for the MAP seems to be biased by the skew in the sampled distribution.\n",
    "\n",
    "Let's turn our attention to the convergence properties of the M-H MCMC sampler. The **acceptance rate** and **rejection rate** are key convergance statistics for the M-H alorithm. A low acceptance rate and high rejection rate are signs of poor convergane. Execute the code in the cell below which computes and displays these statistics and examine the results.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Acceptance/Reject rate:\n",
    "cat('Acceptance rate =', accept_count/chain_length, '\\n')\n",
    "cat('Rejection rate =', reject_count/chain_length, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "These statistics indicate good convergance with a fairly low rejection rates.\n",
    "\n",
    "Another way to evaluate the convergance of MCMC algorithms is to look at the **trace** of the samples. The trace is a plot of the sample value with sample number. The code in the cell below plots the trace for both the $x$ and $y$ samples, including the burn-in period. Execute this code and examine the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Always look at the chain, we would like random noise centered around means\n",
    "par(mfrow = c(2,1))\n",
    "plot(x_chain, type=\"l\", main = 'X chain', ylab = 'Value')\n",
    "plot(y_chain, type=\"l\", main = 'Y chain', ylab = 'Value')\n",
    "par(mfrow = c(1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Examine these sample traces. Notice that there is a significant excersion during the inital burn-in period. After the inital burn-in you can see that the sampling wanders around the mode of the distribution, as it should. \n",
    "\n",
    "Let's look at a close-up view the portion of these traces just after the burn-in period. The code in the cell below plots samples 1000 to 2000. Execute this coded and examine the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Look at a shorter segment of the chain\n",
    "# Always look at the chain, we would like random noise centered around means\n",
    "par(mfrow = c(2,1))\n",
    "plot(x_chain[1000:2000], type=\"l\", main = 'X chain', ylab = 'Value')\n",
    "plot(y_chain[1000:2000], type=\"l\", main = 'Y chain', ylab = 'Value')\n",
    "par(mfrow = c(1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that, for the most part, the samples are centered on the MAP for $x$ and $y$. This is the ideal behavior of the M-H algorithm. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Gibbs Sampling and Hierarchical Models\n",
    "\n",
    "With some experience with the Metropolious-Hastings MCMC algotithm, let's try a Bayes hierarchical model example using Gibbs sampled MCMC. Heirarchical models can be quite complex and provide a great deal of flexibility. The Gibbs sampler can provide a significant improvement in efficiency over the Metropolous-Hastings algorthm. \n",
    "\n",
    "### Gibbs sampling\n",
    "\n",
    "The Metropolis Hastings algorithm is a useful tool. However, this algorithm can suffer from slow convergence for several reasons:\n",
    "\n",
    "- Samples from the M-H algorithm generally have a fairly high serial correlation. This problem results from taking steps in random directions.\n",
    "- As already mentioned, we need to ‘tune’ the state selection probability distribution used to find the next point. For example if we use Normal distribution we must pick $\\sigma$. If $\\sigma$ is too small, the chain will only search the space slowly, with small jumps. If $\\sigma$ is too big, there are large jumps which slow convergence.\n",
    "\n",
    "The Gibbs sampler (Geman and Geman, 1984) is an improved MCMC sampler which speeds convergance. The basic Gibbs sampler algorithm has the following steps:\n",
    "\n",
    "1. For an N dimensional parameter space, $\\{ \\theta_1, \\theta_2, \\ldots, \\theta_N \\}$, find a random starting point. \n",
    "2. Starting with dimension $1$, cycle through each dimension in order, $\\{1, 2, 3, \\ldots, N\\}$:  \n",
    "  - Sample the marginal distribution of the parameter based on the probability distribution of the parameter given the data and other parameter values:\n",
    "  $$p(\\theta_1|D, \\theta_2, \\theta_3, \\ldots, \\theta_N)\\\\ \n",
    "  where\\\\\n",
    "  D\\ is\\ the\\ data$$\n",
    "  - Repeat this sampling proceedure for each remaining dimension in order, $\\{2, 3, \\ldots, N\\}$.\n",
    "4. Repeat step 2 until convergance.    \n",
    "\n",
    "From this simplifed description of the Gibbs sampling algorithm you can infer:\n",
    "\n",
    "- When compared to the Metropolis-Hastings algorithm, the Gibbs sampler reduces serial correlation owing to the reduced round-robin nature of the sampling.   \n",
    "- There are no tuning parameters since sampling is based on the marginals of the likelihood."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hierarchical modeling example\n",
    "\n",
    "In this case, we will under take a univariate regression problem using synthetic data. The regression model has two parameters a slope and an intercept. The variance of the data is an additionl 'nuisance' parameter. To compute these parameters, accounting for their dependency, we will use a hierarchical Bayes model. \n",
    "\n",
    "Heirarchical Bayes models depend on the **chain rule** for Bayes theorem. The chain rule allows us to expand Bayes theorm to accommodate multi-parameter models. We can write the basic chain rule for Bayes theorem like this:\n",
    "\n",
    "$$p(\\theta, \\sigma | D) \\propto p(D| \\theta, \\sigma) p(\\theta, \\sigma)\\\\\n",
    "\\propto p(D | \\theta) p(\\theta | \\sigma) p(\\sigma)\\\\\n",
    "\\propto\\ Likelihood\\ *\\ Prior\\ of\\ \\theta\\ given\\ \\sigma\\ *\\ Prior\\ of\\ \\sigma$$\n",
    "\n",
    "As you can see, a complex multi-parameter Bayesian model is transformed to a hierarchy. The hierarchy is a chain of prior distributions (unconditional and conditional) and a likelihood dependent only on one parameter.  \n",
    "\n",
    "As a first step the code in the cell below generates bi-variate data with Normally distributed errors and plots the result. Execute this code to compute the data.     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Set up the data set as a regression problem\n",
    "require('rjags')\n",
    "N <- 1000\n",
    "x <- 1:N\n",
    "epsilon <- rnorm(N, 0, 100)\n",
    "y <- x + epsilon\n",
    "\n",
    "plot(x, y, main = 'Synthetic data for Bayes regression problem')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The regression model has two parameters, a slope and an intercept, which we will call $a$ and $b$. We will use a **hierarchical Bayes model**. The model is considered hierarchical since the quantity we really want to know, the posterior distribution of the label, which we will refer to as $\\hat{y}$, depends on the distribution of other model parameters. In this case, the posterior distribution of $\\hat{y}$ depends on both the regression coeficients and an error term. We can visualize the hierarchical relationships in this model in the diagram below.\n",
    "\n",
    "![](img/HierarchicalModel.jpg)\n",
    "<center> **Hierarchical model for the posterior distribution of y** </center>\n",
    "\n",
    "In mathematical terms we can define the hierarchical model as follows:\n",
    " \n",
    "1. The prior of the dispursion, $\\sigma$, of the Power distribution is defined as the Uniform distribution:\n",
    "$$U(0, 100)$$\n",
    "2. The variance (dispersion) of the label values is modeled as an Power distribution:\n",
    "$$\\tau = a x^\\sigma = -2 x^\\sigma$$\n",
    "3. The prior distributions of the regression model, $a$ and $b$, are modeled as Normal distributions:\n",
    "$$N(0, 0.01)$$\n",
    "4. The regression model for estimating $\\hat{y_i}$ is defined by:\n",
    "$$\\hat{y_i} = a + b x_i$$\n",
    "5. The posterior distribution of the label values is modeled as a Normal distribution:\n",
    "$$N(\\hat{y_i}, \\tau)$$\n",
    "\n",
    "### Computing the model with JAGS\n",
    "\n",
    "To compute the MCMC samples we will use the JAGS (Just Another Gibbs Sampler) package. JAGS is a multi-platform derivative of the BUGS language (Bayesian inference Using Gibbs Sampling), and is based on the BUGS language. \n",
    "\n",
    "The JAGS model is defined in the `example.bugs` file. The model model definition in this file is shown here:\n",
    "\n",
    "```\n",
    "model\n",
    "{\n",
    "\tfor (i in 1:N)\n",
    "\t{\n",
    "\t\ty[i] ~ dnorm(y.hat[i], tau)\n",
    "\t\ty.hat[i] <- a + b * x[i]\n",
    "\t}\n",
    "\ta ~ dnorm(0, .01)\n",
    "\tb ~ dnorm(0, .01)\n",
    "\ttau <- pow(sigma, -2)\n",
    "\tsigma ~ dunif(0, 100)\n",
    "}\n",
    "```\n",
    "\n",
    "Notice that the model definition in the BUGS lanuage works from the bottom of the heirarchy up. \n",
    "\n",
    "With the model defined we need to execute it using `rjags` package. This package orchestrates the execution of JAGS models from R. The cell below contains the code to compile our JAGS model. The `jags.model` function requires the following arguments:\n",
    "\n",
    "1. The path to the .bugs file.\n",
    "2. A list with the data, x, y, and the number of cases.\n",
    "3. The number of chains to use for the MCMC sampling.\n",
    "4. The number 'burn-in' samples.\n",
    "\n",
    "Execute this code to compile and run the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Run the jags model\n",
    "path = 'C:\\\\Users\\\\StevePC2\\\\Documents\\\\Git\\\\DataScience350\\\\Lecture9' # SET YOUR PATH HERE!!\n",
    "full.path = file.path(path, 'example.bug')\n",
    "jags.mod.reg <- jags.model(full.path,\n",
    "                   data = list('x' = x,\n",
    "                               'y' = y,\n",
    "                               'N' = N),\n",
    "                   n.chains = 4,\n",
    "                   n.adapt = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**Your turn.** Use a reduced size data set of 50 samples to compute another Bayesian regression model. Ensure you do the following:\n",
    "1. Use the R `sample` function to create an index for the samples of `x` and `y`.\n",
    "2. You may wish to plot your sampled data to ensure your sampling worked as desired.\n",
    "3. Use another name for your model.\n",
    "4. Set `N` to 50 in the data list.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the model\n",
    "\n",
    "With the model compiled and the posterior sampled, we can now extract the samples. The `coda.samples` function extracts the samples from Markov chain in a form usable by the coda package. Execute this code to extract the samples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Compute some samples\n",
    "samples <- coda.samples(jags.mod.reg,\n",
    "                        c('a', 'b'),\n",
    "                        1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**Your turn.** Extract samples for the model you created with 50 data points. Make sure you give another name to these samples. \n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now examine the convergance properties of the Gibbs sampled MCMC. As a first step, the code below plots the traces of chains (4) and the marginal density of the slope and intercept parameters, $a$ and $b$. Execute this code and examine the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "library(coda)\n",
    "plot(samples) # Plot the result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine these plots, noting the following:\n",
    "\n",
    "1. The trace plots show the path of the 4 MCMC chains for the $a$ and $b$ model parameters in dotted lines.\n",
    "2. The solid lines show the rolling value of the MAP.\n",
    "3. The density plot for the $a$ and $b$ model parameters are shown on the left. The MAP value of the intercept is close to the actual value of  0.0, and the MAP value of the slope is close to the actual value of 1.0.\n",
    "4. The rug plot at the base of the density plots shows the density of the samples. \n",
    "\n",
    "***\n",
    "**Your turn.** Plot the samples you extracted from the model computed with 50 data points. How do these results compare the model computed with 1000 data points.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coda samples have a summary method. Execute the code in the cell below to print the summary of the Gibbs MCMC sampling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "summary(samples) # Summary statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Coda summary shows a lot of useful informaiton, including:\n",
    "\n",
    "1. The first block shows the properties of the Markov chain.\n",
    "2. The second block contains the values of the coeficients along with error metrics which include: \n",
    "  - The standard deviation (SD) of the coeficient values. In this case you can see that the interecpt, $a$, is close to 0, where as the slope, $b$ is significant.\n",
    "  - The sampling error (SE) is the error arrising from the MCMC sampling.\n",
    "  - The time series SE is the sampling error adjusted for serial correlation in the Markov chain.\n",
    "3. The third block is a table of quantiles for the model parameters. In this case, the conclusions are similar to the ones possible from the SD. \n",
    "\n",
    "***\n",
    "**Your turn.** Display the summary of the model you created with 50 data points. Compare the results to the model computed using 1000 data points.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compaire the results from Gibbs MCMC samples with a conventional linear model. The code in the cell below computes a linear model and prints the summary. Execute this code and compare the results to the Gibbs MCMC sample results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lm.mod = lm(y ~ x, data = data.frame(x = x, y = y))\n",
    "summary(lm.mod)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values and error estimates for the intercept and  slope parameters from the conventional linear model are close to those obtained with Gibbs MCMC sampling. However, the linear model provides no information on the  posterior distribution beyond these simple metrics. For example, there are no quantiles for the coefficients. \n",
    "\n",
    "***\n",
    "**Your turn.** Compute and print the summary of a linear model for the 50 data points you used for your Bayesian model. Compare the results to the Bayesian model and the linear model computed using 1000 data points.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to examine the convergence of a Markov is to plot the cumulative values of the coefficients and their standard deviation vs. the sample number. The `cumuplot` function creates just such a plot for a coda Markov chain. Execute the code in the cell below and examine the results for each chain. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cumuplot(samples) # Cumulative mean for each chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plots show that each chain converges to similar values and with similar standard deviations. This indicates that the Gibbs sampled Markov chains are converging properly.\n",
    "\n",
    "A plot of the **Gelman-Rudin statistic** (Gelman and Rudin, 1992) measures the ratio of the **variance shrinkage between chains** to the **variance shrinkage within chains**. The Gelman-Rudin statistic should coverge to 1.0. The code in the cell below uses the `gelman.plot` function to produce a plot of the Gelman-Rudin statistic and its 97.5% credible interval vs. sample number. Execute this code and examine the result. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gelman.plot(samples) # Gelman convergence plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plots show good convergance of the Markov chains for both model parameters. The Gelman-Rundin statistics converge to 1.0 as does the credible interval. \n",
    "\n",
    "As we already discussed, the convergance of MCMC algorithms is slowed by **autocorrelation** between the samples. The Coda package contains two functions for examining the autocorrelation in Markov chains. The `autocorr.diag` provides a table of average autocorrelation values by model parameter, The `autocorr.plot` function creates autocorrelation function plots for each parameter and chain combination. To examine the results for the Gibbs sampled Markov chain execute the code in the cell below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Look at the autocorrelation of the chain\n",
    "autocorr.diag(samples)\n",
    "autocorr.plot(samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that there are a several significant lag values of the ACF. This means that the convergence of the Markov chains was impeded by this autocorrelation.\n",
    "\n",
    "Given the significant autocorrelation in the samples, we can compute an **effective sample size or ESS**. If there is significant autocorrelation the ESS will be significantly less than the raw sample size. We can compute the ESS as follows:\n",
    "\n",
    "$$ESS = \\frac{N}{1 + 2 \\sum_k ACF(k)}$$\n",
    "\n",
    "The code in the cell below computes the ESS and rejection rate for the Gibbs sampled Markov chain. Execute this code and examine the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## What is the effective size of the sample?\n",
    "effectiveSize(samples) \n",
    "rejectionRate(samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "You can see that the effective sample size is much lower than the raw sample size. Still, the effective sample sizes appears to be sufficient to provide good estimates of the posterior distributions of the parameters. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook you have done the following:\n",
    "\n",
    "- Reviewed the basic properties of a Markov process.\n",
    "- Perform a simple Markov chain Monte Carlo using the Metropolious-Hastings algorithm.\n",
    "- Created and computed a hierarchical Bayes model using Gibbs sampling.\n",
    "- Evaluated the convergance of the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Copyright 2017, Stephen F Elston. All rights reserved. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
