{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bootstrap and Resample Methods\n",
    "\n",
    "### Data Sciene 350\n",
    "\n",
    "### Stephen Elston\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Bootstrap and resampling are widely applicable statistical methods which relax many of the assumptions of clasical statistics. Resampling methods draw heavily on the CLT. Specifically resampling methods:\n",
    "\n",
    "- Allow computation of statistics from limited data\n",
    "- Compute statistic from multiple subsamples of dataset\n",
    "- Minimal distribution assumptions\n",
    "- Computationally intensive\n",
    "\n",
    "Commonly used resampling methods include:\n",
    "\n",
    "- Randomization or Permutation methods: e.g. Fisher's exact test\n",
    "- Bootstrap: resample with equivalent size and replacement\n",
    "- Jackknife: leave one out resampling\n",
    "- Cross validation: resample into folds without replacement\n",
    "\n",
    "\n",
    "## Pitfalls\n",
    "\n",
    "But, there is no magic involved. When using resampling methods always keep in mind the several pitfalls:\n",
    "- If sample is biased, resample statistic is biased\n",
    "- Sample variance and Cis are no better than sample allows\n",
    "\n",
    "![](img/Tobaco.png)\n",
    "\n",
    "<center>**Misuse of inference**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## History\n",
    "\n",
    "### Randomization and permutation methods\n",
    "\n",
    "Randomization and permutation methods were pioneered by Fisher as early as 1911. Fisher fully developed the theory in his 1935 book. Scalability of these methods remain limited, even with modern computers. \n",
    "\n",
    "### Cross-validaton\n",
    "\n",
    "Cross-validation was origianlly proposed by Kurtz in 1948. Mosier extended the method to double cross validation in 1951. The modern method of nested or multicoross-validation were introduced by Krus and Fuller in 1982. Today, cross-validation is widely used in the testing of machine learning models. \n",
    "\n",
    "### Jack knife methods\n",
    "\n",
    "Maurice Quenouille originally suggested this method in 1949. The jack knife was fully developed\n",
    "by John W. Tukey, who gave the method its name, in 1958. Tukey saw that method as a simple tool useful for many purposes like a pocket knife. \n",
    "\n",
    "\n",
    "### Bootstrap \n",
    "\n",
    "The bootstrap method was first suggested by Efron and Hinkley in 1978 and further developed by Efron in 1979. A full treatment was provided in Efron's 1980 book. \n",
    "\n",
    "![](img/Efron1980.jpg)\n",
    "\n",
    "![](img/2014_Efron-outdoors.jpg)\n",
    "\n",
    "With increased computing power, use of bootstrap methods continues to expand. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview of the bootstrap\n",
    "\n",
    "The bootstrap method \n",
    "\n",
    "- Re-compute statistic many times with sample \n",
    "- Randomly sample (e.g. Bernoulli sample) data with replacement\n",
    "- Subsamples have the same size as original sample\n",
    "- Works with any statistic â€¦ in principle\n",
    "\n",
    "For example, you can compute the bootstrap mean as:\n",
    "\n",
    "$$Meanboot = \\frac{\\Sigma_i mean(sample_i)}{nsample}\\\\\n",
    "where,\\ for\\ example\\ with\\ 10\\ samples,\\\\\n",
    "sample_i = X_1 + X_2 + X_3 + X_4 + X_5 + X_6 + X_7 + X_8 + X_1 + X_5$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bootstrap example\n",
    "\n",
    "Let's try a fist example. You will bootstrap the means of the hights of different populations from Galton's height data. This is an example of a parametric bootstrap estimate. Parametric because our model has a parameter, the mean, we are trying to estimate. \n",
    "\n",
    "As a first step, the code in the cell below divides the data set by male and female adult childern, and then plots the distributions with the means of the two populations. Run this code and examine the results>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "library(HistData)\n",
    "library(resample)\n",
    "library(simpleboot)\n",
    "\n",
    "male = GaltonFamilies[GaltonFamilies$gender == 'male',]\n",
    "female = GaltonFamilies[GaltonFamilies$gender == 'female',]\n",
    "\n",
    "plot.dists <- function(a, b, cols = c('pop_A', 'pop_B'), nbins = 20){\n",
    "  dat = c(a,b)\n",
    "  maxs = max(dat, na.rm = TRUE)\n",
    "  mins = min(dat, na.rm = TRUE)\n",
    "  breaks = seq(maxs, mins, length.out = (nbins + 1))\n",
    "  par(mfrow = c(2, 1))\n",
    "  hist(a, breaks = breaks, main = paste('Histogram of', cols[1]), xlab = cols[1])\n",
    "  abline(v = mean(a), lwd = 4, col = 'red')\n",
    "  hist(b, breaks = breaks, main = paste('Histogram of', cols[2]), xlab = cols[2])\n",
    "  abline(v = mean(b), lwd = 4, col = 'red')\n",
    "  par(mfrow = c(1, 1))\n",
    "}\n",
    "\n",
    "plot.dists(male$childHeight, female$childHeight, cols = c('sons', 'daughters'), nbins = 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that the distributions of the heights of the sons and daughters overlap. But, are the means significantly different.\n",
    "\n",
    "### Boot strap the means\n",
    "\n",
    "The code in the cell below uses the `one.boot` function from the R `simpleboot` package to compute the bootstrap distribution of the means of the heights of the sons and daughters. The rest of the code plots the results of the two bootstrap estimates, including the 95% confidence interval for the estimates. Run this code and examine the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot.hist <- function(a, maxs, mins, cols = 'difference of means', nbins = 80, p = 0.05) {\n",
    "  breaks = seq(maxs, mins, length.out = (nbins + 1))\n",
    "  hist(a, breaks = breaks, main = paste('Histogram of', cols), xlab = cols)\n",
    "  abline(v = mean(a), lwd = 4, col = 'red')\n",
    "  abline(v = 0, lwd = 4, col = 'blue')\n",
    "  abline(v = quantile(a, probs = p/2), lty = 3, col = 'red', lwd = 3)  \n",
    "  abline(v = quantile(a, probs = (1 - p/2)), lty = 3, col = 'red', lwd = 3)\n",
    "}\n",
    "\n",
    "plot.t <- function(a, b, cols = c('pop_A', 'pop_B'), nbins = 80, p = 0.05){\n",
    "  maxs = max(c(max(a), max(b)))\n",
    "  mins = min(c(min(a), min(b)))\n",
    "  par(mfrow = c(2, 1))\n",
    "  plot.hist(a, maxs, mins, cols = cols[1])\n",
    "  plot.hist(b, maxs, mins, cols = cols[2])\n",
    "  par(mfrow = c(1, 1))\n",
    "}\n",
    "\n",
    "## Bootstrap the mean of the sons and of daughters\n",
    "mean.boot.male = one.boot(male$childHeight, mean, R = 100000)\n",
    "mean.boot.female = one.boot(female$childHeight, mean, R = 100000)\n",
    "plot.t(mean.boot.male$t, mean.boot.female$t, nbins = 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution of the bootstrap means do not overlap at all. Evidently, the difference is significant. \n",
    "\n",
    "**Your turn:** Compute and plot the bootstrap distribution of the mean of the hights of the fathers. Compare this estimate to the bootstrap estimate of the mean of the heights of the sons. Are these means significantly different? Hint; use the `one.boot` function followed by the `plot.t` function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean.boot.father = one.boot(male$father, mean, R = 100000)\n",
    "plot.t(mean.boot.male$t, mean.boot.father$t, nbins = 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bootstrap difference in means\n",
    "\n",
    "In the previous example you computed and compared two bootstrap distributions of the means from the height data. It is actually quite easy to bootstrap a statistic such as the difference in means. \n",
    "\n",
    "The code in the cell below uses the `two.boot` function to compute the bootstrap difference in means of two populations, sons and daughters. Run the code in this cell and examine the plotted results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Bootstrap the difference in means of sons and daughters\n",
    "plot.diff <- function(a, cols = 'difference of means', nbins = 80, p = 0.05){\n",
    "  maxs = max(a)\n",
    "  mins = min(a)\n",
    "  plot.hist(a, maxs, mins, cols = cols[1])\n",
    "}\n",
    "\n",
    "require(repr)\n",
    "options(repr.plot.width=6, repr.plot.height=4)\n",
    "\n",
    "two.boot.mean = two.boot(male$childHeight, female$childHeight, mean, R = 100000)\n",
    "plot.diff(two.boot.mean$t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution of the difference in means is far from zero. As before, we can infer that the means of the two populations are significantly different. \n",
    "\n",
    "But, is the distribution of the difference in means Normal as implied by the CLT. Run the code in the cell below to create a Q-Q Normal plot of the bootstrap distribution of the difference in means and examine the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Is the bootstrapped distribution Normal?\n",
    "options(repr.plot.width=6, repr.plot.height=6)\n",
    "qqnorm(two.boot.mean$t, main = 'Quantiles of standard Normal vs. bookstrapped mean')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The points on the Q-Q Normal plot are nearly on a strait line. Apparently, the bootstrap distribution of the difference in means does conform to the CLT.\n",
    "\n",
    "**Your Turn:** In the cell below, create and run the code to compare the difference in means of adult sons to their fathers. Is the difference significant? Also, check if the distribution in the difference in means is approximately Normal. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "two.boot.father= two.boot(male$childHeight, male$father, mean, R = 100000)\n",
    "plot.diff(two.boot.father$t)\n",
    "qqnorm(two.boot.father$t, main = 'Quantiles of standard Normal vs. bookstrapped mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstraping other statistics\n",
    "\n",
    "The bootstrap method can be applied to most any statistic. The code in the cell below computes the differnce in medians of the sons and the fathers. The median is an order statistic, and the values of a median are descretized by the quanta of the samples. Run this code and examine the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Bootstrap the difference in medians of sons and fathers\n",
    "options(repr.plot.width=6, repr.plot.height=4)\n",
    "two.boot.median = two.boot(male$childHeight, male$father, median, R = 100000)\n",
    "plot.diff(two.boot.median$t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The chart shows that the bootstrap distribution of the difference in medians. The confidence interval overlaps zero, so we must accept the null hypothesis that the difference in medians is zero.\n",
    "\n",
    "You can also plot the Q-Q Normal plot of the bootstrap distribution of the difference in medians. Run the code in the cell below and examine the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Is the bootstrapped distribution Normal?\n",
    "qqnorm(two.boot.median$t, main = 'Quantiles of standard Normal vs. bookstrapped median')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep in mind that the CLT only applies to sample means, not medians or any other statistic. None the less, you can see that the Q-Q Normal plot of the bootstrap distribution of the difference in meadians tends down the center diagonal of the plot. The zig-zag behavior arrises from the quanitzation inherent in the median."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Jack Knife\n",
    "\n",
    "The jack knife is another resampline method. The jack knife is related to the bootstrap, but is a bit more restrictive in its applicaiton. Spcifically, the jack knife:\n",
    "\n",
    "- Re-computes a statistic N times with leave one out sample, where N is the sample size.\n",
    "- Uses Random leave one (or n) out sampling.\n",
    "- Only works for statistics with continuous derivatives.\n",
    "\n",
    "For example, you can compute the bootstrap mean as:\n",
    "\n",
    "$$MeanJK = \\frac{\\Sigma_i mean(sample_i)}{nsample}\\\\\n",
    "where,\\ for\\ example\\ with\\ 10\\ samples,\\\\\n",
    "sample_i = X_1 + X_2 + X_3 + X_4 + X_5 + X_6 + X_8 + X_9 + X_{10}$$\n",
    "\n",
    "A simple example of using a jack knife estimation of a mean is shown in the cell below. Run this code, examine the results and compare them to those obtainted with the bootstrap. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Jackknife the mean of the sons and of daughters\n",
    "mean.jack.male = jackknife(male$childHeight, mean)\n",
    "mean.jack.male$stats\n",
    "mean.jack.female = jackknife(female$childHeight, mean)\n",
    "mean.jack.female$stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation\n",
    "\n",
    "Cross validation is a leave many out resampling technique. Cross validation uses multiple non-overlapping subsamples to train and test a data set. Basic cross validation uses the following steps:\n",
    "\n",
    "- Divide dataset into N subsamples \n",
    "- N â€“ 1 Folds train model \n",
    "- One Fold evaluate model\n",
    "\n",
    "The basic concept of cross validation is illustrated below. \n",
    "\n",
    "![](img/CrossValidation.jpg)\n",
    "\n",
    "Model performance is performed by looking at agregated summary statistics across the the trained models using the test data for each resample. The resampling reduces bias in the model performance statistics. Most importantly, cross validation reduces unpleasant suprises when a model is placed in production. \n",
    "\n",
    "The jack knife is an extreem end member of the family of cross validation methods. With the jack knife, the number of folds equals the number of data points. \n",
    "\n",
    "There are several variations on cross validation. The most commonly used in **nest cross validation**. In nested cross validaton, cross validation is performed on one or more models to compare performance.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Copyright 2017, Stephen F Elston. All rights reserved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.3.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
